{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(X)CS224W - End to End - Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import gzip\n",
    "\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.models.lightgcn import LightGCN\n",
    "\n",
    "from e2e.datasets import SpotifyMPDataset, EdgeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_dataset = SpotifyMPDataset(\n",
    "    root='./spotify_mpd', \n",
    "    url=f\"file://{osp.join(Path('.').resolve(), 'spotify_preprocessed_dataset')}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spotify_dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = spotify_dataset[1]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 3,\n",
    "    'hidden_dim': train_data.num_node_features,\n",
    "    'batch_size': 1024,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 10,\n",
    "    'lambda_reg': 1e-4,\n",
    "    'k': 500\n",
    "}\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(\n",
    "    num_nodes=test_data.num_nodes,\n",
    "    embedding_dim=train_data.num_node_features,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "# Initialize the embeddings with the initial features from the full graph\n",
    "model.embedding.weight.data = test_data[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_file(recommended_track_ids, filename):\n",
    "\n",
    "    lines = ['\\n']\n",
    "\n",
    "    team_line = \"team_info, SH_XCS224W_Summer_2023, hurubaru@stanford.edu\"\n",
    "\n",
    "    lines.append(team_line)\n",
    "\n",
    "    recommended_track_uris = itemgetter(torch.flatten(recommended_track_ids))(spotify_dataset.track_uri_map)\n",
    "    \n",
    "    for i, playlist_node_id in enumerate(test_data[\"test_nodes_index\"]):\n",
    "        pid = spotify_dataset.playlist_id_map.get(playlist_node_id)\n",
    "        line = ', '.join([pid] + [track_uri for track_uri in recommended_track_uris[i*args[\"k\"]:(i+1)*args[\"k\"]]])\n",
    "        lines.append(line)\n",
    "\n",
    "    lines.append('\\n')\n",
    "\n",
    "    output_str = '\\n'.join([line for line in lines])\n",
    "\n",
    "    output_bytes = output_str.encode('utf-8')\n",
    "\n",
    "    with gzip.open(filename, 'w') as fout:\n",
    "        fout.write(output_bytes)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "\n",
    "    test_edge_index = test_data.edge_index.to(device=args[\"device\"])\n",
    "\n",
    "    track_nodes_mask = test_data[\"node_type\"] == test_data[\"track_node_type\"]\n",
    "    track_node_index = torch.masked_select(test_data[\"node_type\"], track_nodes_mask).to(args[\"device\"])\n",
    "\n",
    "    recommended_track_ids = torch.empty((0, 500), dtype=torch.long)\n",
    "\n",
    "    tqdm_epoch_bar = trange(args[\"epochs\"], desc='Evaluating: ', leave=True)\n",
    "    for _ in tqdm_epoch_bar:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        playlist_index = test_data[\"test_nodes_index\"]\n",
    "\n",
    "        edge_index_data = EdgeDataset(playlist_index)\n",
    "\n",
    "        data_loader = DataLoader(edge_index_data, batch_size=args[\"batch_size\"], shuffle=False, pin_memory=True, num_workers=0)\n",
    "        \n",
    "        for step, (batch_playlist_index, _, _) in enumerate(data_loader):\n",
    "\n",
    "            out = model.recommend(edge_index=test_edge_index, src_index=batch_playlist_index, dst_index=track_node_index, k=args[\"k\"]).cpu()\n",
    "\n",
    "            recommended_track_ids = torch.concatenate([recommended_track_ids, out], dim=0)\n",
    "\n",
    "            tqdm_epoch_bar.set_description(f\"Evaluating: (Step - {step})\")\n",
    "            tqdm_epoch_bar.refresh()\n",
    "\n",
    "    return recommended_track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    model.to(device=args[\"device\"])\n",
    "\n",
    "    train_edge_index = train_data.edge_index.to(device=args[\"device\"])\n",
    "\n",
    "    tqdm_epoch_bar = trange(args[\"epochs\"], desc='Training: ', leave=True)\n",
    "\n",
    "    for epoch in tqdm_epoch_bar:\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        playlist_index, pos_track_index, neg_track_index = structured_negative_sampling(train_data.edge_index, contains_neg_self_loops=False)\n",
    "\n",
    "        edge_index_data = EdgeDataset(playlist_index, pos_track_index, neg_track_index)\n",
    "\n",
    "        data_loader = DataLoader(edge_index_data, batch_size=args[\"batch_size\"], shuffle=True, pin_memory=True, num_workers=0)\n",
    "        \n",
    "        for step, (batch_playlist_index, batch_pos_track_index, batch_neg_track_index) in enumerate(data_loader):\n",
    "\n",
    "            batch_pos_edge_index = torch.stack([batch_playlist_index, batch_pos_track_index], dim=0)\n",
    "            batch_neg_edge_index = torch.stack([batch_playlist_index, batch_neg_track_index], dim=0)\n",
    "\n",
    "            batch_edge_index = torch.concatenate([batch_pos_edge_index, batch_neg_edge_index], dim=-1).to(device=args[\"device\"])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(edge_index=train_edge_index, edge_label_index=batch_edge_index).cpu()\n",
    "\n",
    "            pos_edge_rank, neg_edge_rank = out.chunk(2)\n",
    "            \n",
    "            loss = model.recommendation_loss(pos_edge_rank, neg_edge_rank, lambda_reg=args[\"lambda_reg\"])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tqdm_epoch_bar.set_description(f\"Training: (BPRLoss - {loss.item()})\")\n",
    "            tqdm_epoch_bar.refresh()\n",
    "\n",
    "    \n",
    "        # Get the recommended track ids for the test set\n",
    "        recommended_track_ids = test()\n",
    "\n",
    "        generate_output_file(recommended_track_ids, filename=f'epoch_{epoch}_submission.csv.gz')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XCS224W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
